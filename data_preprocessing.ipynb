{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                  Neighborhood  Mean_Agg_Score\n0                        b'Northridge_Heights'       40.008696\n1                               b'Stone_Brook'       38.850000\n2                                b'Northridge'       37.629630\n3                                    b'Greens'       37.142857\n4                       b'Bloomington_Heights'       37.083333\n5                                   b'Veenker'       37.052632\n6                                   b'Blueste'       36.333333\n7                                b'Timberland'       36.222222\n8                                  b'Somerset'       35.431818\n9                                  b'Crawford'       33.828571\n10                            b'College_Creek'       33.766990\n11                                  b'Gilbert'       33.620968\n12                              b'Clear_Creek'       32.833333\n13                           b'Northwest_Ames'       31.739583\n14                              b'Sawyer_West'       31.083333\n15                                 b'Mitchell'       29.734940\n16                          b'Northpark_Villa'       29.470588\n17                                 b'Landmark'       29.000000\n18                              b'Green_Hills'       29.000000\n19                               b'North_Ames'       28.787879\n20                                b'Brookside'       28.651163\n21                                 b'Old_Town'       28.377049\n22  b'South_and_West_of_Iowa_State_University'       28.055556\n23                                   b'Sawyer'       28.037383\n24                                  b'Edwards'       27.834483\n25                           b'Meadow_Village'       26.766667\n26                                b'Briardale'       26.333333\n27                   b'Iowa_DOT_and_Rail_Road'       24.863014",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Neighborhood</th>\n      <th>Mean_Agg_Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b'Northridge_Heights'</td>\n      <td>40.008696</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b'Stone_Brook'</td>\n      <td>38.850000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b'Northridge'</td>\n      <td>37.629630</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b'Greens'</td>\n      <td>37.142857</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b'Bloomington_Heights'</td>\n      <td>37.083333</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>b'Veenker'</td>\n      <td>37.052632</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>b'Blueste'</td>\n      <td>36.333333</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>b'Timberland'</td>\n      <td>36.222222</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>b'Somerset'</td>\n      <td>35.431818</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>b'Crawford'</td>\n      <td>33.828571</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>b'College_Creek'</td>\n      <td>33.766990</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>b'Gilbert'</td>\n      <td>33.620968</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>b'Clear_Creek'</td>\n      <td>32.833333</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>b'Northwest_Ames'</td>\n      <td>31.739583</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>b'Sawyer_West'</td>\n      <td>31.083333</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>b'Mitchell'</td>\n      <td>29.734940</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>b'Northpark_Villa'</td>\n      <td>29.470588</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>b'Landmark'</td>\n      <td>29.000000</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>b'Green_Hills'</td>\n      <td>29.000000</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>b'North_Ames'</td>\n      <td>28.787879</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>b'Brookside'</td>\n      <td>28.651163</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>b'Old_Town'</td>\n      <td>28.377049</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>b'South_and_West_of_Iowa_State_University'</td>\n      <td>28.055556</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>b'Sawyer'</td>\n      <td>28.037383</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>b'Edwards'</td>\n      <td>27.834483</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>b'Meadow_Village'</td>\n      <td>26.766667</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>b'Briardale'</td>\n      <td>26.333333</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>b'Iowa_DOT_and_Rail_Road'</td>\n      <td>24.863014</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0       33\n1       26\n2       28\n3       34\n4       34\n        ..\n2188    25\n2189    28\n2190    29\n2191    28\n2192    25\nName: All_Quality, Length: 2193, dtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "X_train = pd.read_csv('x_train_cleaned.csv')\n",
    "X_test = pd.read_csv('x_test_cleaned.csv')\n",
    "y_train = pd.read_csv('y_train_cleaned.csv')\n",
    "y_test = pd.read_csv('y_test_cleaned.csv')\n",
    "\n",
    "quality_and_conditions=[]\n",
    "\n",
    "for columns in X_train.columns:\n",
    "    if '_Qual' in columns or '_Cond' in columns:\n",
    "        quality_and_conditions.append(columns)\n",
    "\n",
    "quality_and_conditions.remove('Sale_Condition')\n",
    "quality_and_conditions.remove('Low_Qual_Fin_SF')\n",
    "quality_and_conditions.append('Bsmt_Exposure')\n",
    "quality_and_conditions.append('Heating_QC')\n",
    "quality_and_conditions.append('Fireplace_Qu')\n",
    "\n",
    "X_train.loc[:,'All_Quality'] = X_train.loc[:, quality_and_conditions].sum(axis=1)\n",
    "\n",
    "# perform groupby on `Neighborhood`, then aggregate via averaging\n",
    "neighborhood_scores = X_train.loc[:, ['Neighborhood','All_Quality']].groupby('Neighborhood').agg(Mean_Agg_Score=('All_Quality', np.mean))\n",
    "\n",
    "# sort dataframe by descending order of the mean score\n",
    "neighborhood_scores.sort_values(by='Mean_Agg_Score', ascending=False, inplace=True)\n",
    "\n",
    "# extract out neighborhood names from the index\n",
    "neighborhood_scores.loc[:,'Neighborhood'] = neighborhood_scores.index\n",
    "\n",
    "# reset index to the usual numeric form\n",
    "neighborhood_scores.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# re-arrange columns to being Neighborhood to left-most position\n",
    "neighborhood_scores = neighborhood_scores.loc[:, ['Neighborhood', 'Mean_Agg_Score']]\n",
    "\n",
    "display(neighborhood_scores)\n",
    "display(X_train['All_Quality'])\n",
    "\n",
    "def get_score(x):\n",
    "    return neighborhood_scores.loc[neighborhood_scores.loc[:,'Neighborhood']==x,'Mean_Agg_Score'].values[0]\n",
    "\n",
    "# build the newly engineered attribute, call it Neighborhood Score\n",
    "X_train.loc[:,'Neighborhood_Score'] = X_train.loc[:,'Neighborhood']\n",
    "\n",
    "X_test.loc[:,'All_Quality'] = X_test.loc[:, quality_and_conditions].sum(axis=1)\n",
    "# perform groupby on `Neighborhood`, then aggregate via averaging\n",
    "neighborhood_scores = X_test.loc[:, ['Neighborhood','All_Quality']].groupby('Neighborhood').agg(Mean_Agg_Score=('All_Quality', np.mean))\n",
    "\n",
    "# sort dataframe by descending order of the mean score\n",
    "neighborhood_scores.sort_values(by='Mean_Agg_Score', ascending=False, inplace=True)\n",
    "\n",
    "# extract out neighborhood names from the index\n",
    "neighborhood_scores.loc[:,'Neighborhood'] = neighborhood_scores.index\n",
    "\n",
    "# reset index to the usual numeric form\n",
    "neighborhood_scores.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# re-arrange columns to being Neighborhood to left-most position\n",
    "neighborhood_scores = neighborhood_scores.loc[:, ['Neighborhood', 'Mean_Agg_Score']]\n",
    "\n",
    "X_test.loc[:,'Neighborhood_Score'] = X_test.loc[:,'Neighborhood'].apply(get_score)\n",
    "\n",
    "#display(X_train['Neighborhood_Score'])\n",
    "\n",
    "#X_train.drop(columns=['Neighborhood'], inplace=True)\n",
    "#X_test.drop(columns=['Neighborhood'], inplace=True)\n",
    "\n",
    "#Creiamo una nuova feature Total_Qual che è pari alla somma di tutti i campi qualitativi\n",
    "#Creiamo una nuova feature Neighborhood_Score che si basa su Total_Qual per assegnargli un valore qualitativo al posto di nominale"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creiamo una nuova feature Total_Qual che è pari alla somma di tutti i campi qualitativi\n",
    "Creiamo una nuova feature Neighborhood_Score che si basa su Total_Qual per assegnargli un valore qualitativo al posto di nominale\n",
    "\n",
    "TODO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "0       272.0\n1       260.0\n2       429.0\n3       396.0\n4       170.0\n        ...  \n2188      0.0\n2189    336.0\n2190    120.0\n2191    164.0\n2192    112.0\nName: Total_External_SF, Length: 2193, dtype: float64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "porch = ['Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch']\n",
    "X_train.loc[:,'Total_External_SF'] = X_train.loc[:, porch].sum(axis=1)\n",
    "X_test.loc[:,'Total_External_SF'] = X_test.loc[:, porch].sum(axis=1)\n",
    "\n",
    "display(X_train['Total_External_SF'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Total_External_SF\n",
    "Creating a new feature that represents the surface of all porch or decks outside the property, trying to combine similar information into a single feature."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0       2823.0\n1       2238.0\n2       2564.0\n3       2676.0\n4       2536.0\n         ...  \n2188    3894.0\n2189    2546.0\n2190    2410.0\n2191    2011.0\n2192    1307.0\nName: Total_SF, Length: 2193, dtype: float64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "surface = ['Total_Finished_Bsmt_SF', 'First_Flr_SF', 'Second_Flr_SF', 'Garage_Area']\n",
    "\n",
    "X_train['Total_Finished_Bsmt_SF'] = X_train['Total_Bsmt_SF'] - X_train['Bsmt_Unf_SF']\n",
    "X_test['Total_Finished_Bsmt_SF'] = X_test['Total_Bsmt_SF'] - X_test['Bsmt_Unf_SF']\n",
    "\n",
    "X_train.loc[:, 'Total_SF'] = X_train.loc[:, surface].sum(axis=1)\n",
    "X_test.loc[:, 'Total_SF'] = X_test.loc[:, surface].sum(axis=1)\n",
    "#vediamo se fare anche Total senza unfinished\n",
    "\n",
    "display(X_train['Total_SF'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Total_SF\n",
    "Creating a new feature that represents the surface of the inside of the property, trying to combine similar information into a single feature."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0       2.0\n1       1.0\n2       2.0\n3       3.0\n4       3.0\n       ... \n2188    4.0\n2189    3.0\n2190    2.0\n2191    2.0\n2192    2.0\nName: Total_Baths, Length: 2193, dtype: float64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baths = ['Full_Bath', 'Half_Bath', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath']\n",
    "\n",
    "X_train.loc[:, 'Total_Baths'] = X_train.loc[:, baths].sum(axis=1)\n",
    "X_test.loc[:, 'Total_Baths'] = X_test.loc[:, baths].sum(axis=1)\n",
    "\n",
    "display(X_train['Total_Baths'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Total_Baths\n",
    "Creating a new feature that represents the sum of all the types of bathrooms, trying to add new information to the dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0       50.0\n1       49.0\n2       52.0\n3       12.0\n4        9.0\n        ... \n2188    30.0\n2189    29.0\n2190    22.0\n2191    23.0\n2192    14.0\nName: Year_To_Sell, Length: 2193, dtype: float64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train.loc[:,'Year_To_Sell'] = X_train.loc[:,'Year_Sold'] - X_train.loc[:,'Year_Built']\n",
    "X_test.loc[:,'Year_To_Sell'] = X_test.loc[:,'Year_Sold'] - X_test.loc[:,'Year_Built']\n",
    "\n",
    "display(X_train['Year_To_Sell'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Year_To_Sell\n",
    "Creating a new feature that represents the span of years required to sell the house, trying to add new information to the dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_v2 shape after get_dummies: (2193, 254)\n",
      "x_test_v2 shape after get_dummies: (731, 214)\n",
      "'MS_SubClass_b'One_Story_with_Finished_Attic_All_Ages'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'MS_SubClass_b'One_and_Half_Story_PUD_All_Ages'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'MS_Zoning_b'A_agr'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'MS_Zoning_b'I_all'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_b'Green_Hills'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_b'Landmark'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Exterior_1st_b'AsphShn'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Exterior_1st_b'ImStucc'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Exterior_1st_b'PreCast'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Exterior_1st_b'Stone'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Exterior_2nd_b'AsphShn'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Exterior_2nd_b'Other'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Exterior_2nd_b'PreCast'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Mas_Vnr_Type_b'CBlock'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Sale_Type_b'Con'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Bloomington_Heights'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Blueste'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Briardale'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Brookside'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Clear_Creek'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'College_Creek'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Crawford'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Edwards'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Gilbert'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Green_Hills'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Greens'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Iowa_DOT_and_Rail_Road'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Landmark'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Meadow_Village'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Mitchell'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'North_Ames'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Northpark_Villa'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Northridge'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Northridge_Heights'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Northwest_Ames'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Old_Town'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Sawyer'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Sawyer_West'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Somerset'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'South_and_West_of_Iowa_State_University'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Stone_Brook'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Timberland'' found missing in x_test_v2, initialising new column with 0s.\n",
      "'Neighborhood_Score_b'Veenker'' found missing in x_test_v2, initialising new column with 0s.\n",
      "\n",
      "\n",
      "'Neighborhood_Score' found missing in x_train_v2, initialising new column with 0s.\n",
      "'Exterior_2nd_b'CBlock'' found missing in x_train_v2, initialising new column with 0s.\n",
      "'Sale_Type_b'VWD'' found missing in x_train_v2, initialising new column with 0s.\n",
      "\n",
      "\n",
      "Check if both datasets have the same set of columns: True\n",
      "\n",
      "\n",
      "Current number of columns: 257\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.get_dummies(X_train.loc[:,[col for col in X_train.columns]])\n",
    "print('x_train_v2 shape after get_dummies: {}'.format(X_train.shape))\n",
    "X_test = pd.get_dummies(X_test.loc[:,[col for col in X_test.columns]])\n",
    "print('x_test_v2 shape after get_dummies: {}'.format(X_test.shape))\n",
    "\n",
    "for col in X_train.columns:\n",
    "    if col not in X_test.columns:\n",
    "        print('\\'{}\\' found missing in x_test_v2, initialising new column with 0s.'.format(col))\n",
    "        X_test.loc[:,col] = 0\n",
    "print('\\n')\n",
    "for col in X_test.columns:\n",
    "    if col not in X_train.columns:\n",
    "        print('\\'{}\\' found missing in x_train_v2, initialising new column with 0s.'.format(col))\n",
    "        X_train.loc[:,col] = 0\n",
    "print('\\n')\n",
    "print('Check if both datasets have the same set of columns: {}'.format(set(X_train.columns) == set(X_test.columns)))\n",
    "print('\\n')\n",
    "print('Current number of columns: {}'.format(X_train.shape[1]))\n",
    "\n",
    "# ensure that column sequence is similar too\n",
    "column_list = list(X_train.columns)\n",
    "X_test = X_test.loc[:,column_list]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# One Hot Encoding\n",
    "\n",
    "Applying the one hot encoding using the get_dummies function of pandas.\n",
    "Since it's possible that a nominal value is not present in one of the categorical columns, resulting in more or lesser columns generated in train split vs test split.\n",
    "Assuring to reach the same of features by filling with 0 the ones that are missing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "cols = X_train.columns\n",
    "\n",
    "# perform the normalization\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.fit_transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(data=X_train, columns=cols)\n",
    "X_test = pd.DataFrame(data=X_test, columns=cols)\n",
    "\n",
    "X_train.to_csv('x_train_preprocessed.csv', index=False)\n",
    "y_train.to_csv('y_train_preprocessed.csv', index=False)\n",
    "X_test.to_csv('x_test_preprocessed.csv', index=False)\n",
    "y_test.to_csv('y_test_preprocessed.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Standard Scaler\n",
    "Standardizing features by removing the mean and scaling to unit variance (-1, 1). Work best with normal variance features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "\n",
    "cols = X_train.columns\n",
    "\n",
    "# perform the normalization\n",
    "X_train = mm.fit_transform(X_train)\n",
    "X_test = mm.fit_transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(data=X_train, columns=cols)\n",
    "X_test = pd.DataFrame(data=X_test, columns=cols)\n",
    "\n",
    "X_train.to_csv('x_train_preprocessed_minmax.csv', index=False)\n",
    "y_train.to_csv('y_train_preprocessed_minmax.csv', index=False)\n",
    "X_test.to_csv('x_test_preprocessed_minmax.csv', index=False)\n",
    "y_test.to_csv('y_test_preprocessed_minmax.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Min Max Scaler\n",
    "Transforming features by scaling each feature to a given range (0, 1)."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
