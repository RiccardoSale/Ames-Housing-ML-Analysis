{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## ANN Regressor\n",
    "\n",
    "Un fia de roba"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "import pandas as pd\n",
    "\n",
    "X_train = pd.read_csv('x_train_preprocessed_minmax.csv')\n",
    "X_test = pd.read_csv('x_test_preprocessed_minmax.csv')\n",
    "y_train = pd.read_csv('y_train_preprocessed_minmax.csv')\n",
    "y_test = pd.read_csv('y_test_preprocessed_minmax.csv')\n",
    "\n",
    "y_train = y_train.to_numpy().flatten() #y_train flattened, works better\n",
    "\n",
    "oh_neighbor = []\n",
    "for col in X_train.columns:\n",
    "    if 'Neighborhood_b' in col:\n",
    "        oh_neighbor.append(col)\n",
    "\n",
    "X_train.drop(columns=oh_neighbor, inplace=True)\n",
    "X_test.drop(columns=oh_neighbor, inplace=True)\n",
    "\n",
    "porch = ['Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch']\n",
    "surface = ['Total_Finished_Bsmt_SF', 'First_Flr_SF', 'Second_Flr_SF', 'Garage_Area']\n",
    "baths = ['Full_Bath', 'Half_Bath', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath']\n",
    "\n",
    "X_train.drop(columns=porch, inplace=True)\n",
    "X_test.drop(columns=porch, inplace=True)\n",
    "\n",
    "X_train.drop(columns=surface, inplace=True)\n",
    "X_test.drop(columns=surface, inplace=True)\n",
    "\n",
    "X_train.drop(columns=baths, inplace=True)\n",
    "X_test.drop(columns=baths, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "All the feature which have been encoded are removed, this solution significatively reduces the loss parameter."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Network initialization and setup\n",
    "\n",
    "Using single hidden layer with half of the units of the input one.\n",
    "The output layer has a single units due to the necessity to predict only the Sale Price.\n",
    "\n",
    "For the input and hidden layers the activation function chosen is relu because of its good speed of train and simplicity to compute.\n",
    "The output has instead the linear activation function for predicting the float value.\n",
    "\n",
    "The kernel initializer is always normal so it use a normal distribution to generate tensors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(units=189, kernel_initializer='normal', activation='linear', input_shape=[188, ]))\n",
    "model.add(layers.Dense(units=95, kernel_initializer='normal', activation='elu'))\n",
    "model.add(layers.Dense(units=47, kernel_initializer='normal', activation='linear'))\n",
    "model.add(layers.Dense(units=17, kernel_initializer='normal', activation='elu'))\n",
    "model.add(layers.Dense(units=1, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=0.0015, beta_1=0.9, beta_2=0.999, amsgrad=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/140\n",
      "69/69 [==============================] - 1s 1ms/step - loss: 76.4771 - r_square: -5.0893\n",
      "Epoch 102/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 18.5661 - r_square: -4.9460\n",
      "Epoch 103/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 8.7905 - r_square: -4.5784\n",
      "Epoch 104/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 4.8040 - r_square: -4.0252\n",
      "Epoch 105/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 2.7909 - r_square: -3.3676\n",
      "Epoch 106/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.6801 - r_square: -2.6765\n",
      "Epoch 107/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 1.0394 - r_square: -2.0274\n",
      "Epoch 108/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.6605 - r_square: -1.4627\n",
      "Epoch 109/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.4344 - r_square: -1.0026\n",
      "Epoch 110/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.2994 - r_square: -0.6441\n",
      "Epoch 111/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.2190 - r_square: -0.3730\n",
      "Epoch 112/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1717 - r_square: -0.1794\n",
      "Epoch 113/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1438 - r_square: -0.0400\n",
      "Epoch 114/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1276 - r_square: 0.0567\n",
      "Epoch 115/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1182 - r_square: 0.1241\n",
      "Epoch 116/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1127 - r_square: 0.1708\n",
      "Epoch 117/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1091 - r_square: 0.2029\n",
      "Epoch 118/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1066 - r_square: 0.2290\n",
      "Epoch 119/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1048 - r_square: 0.2484\n",
      "Epoch 120/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1031 - r_square: 0.2618\n",
      "Epoch 121/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1016 - r_square: 0.2745\n",
      "Epoch 122/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.1000 - r_square: 0.2859\n",
      "Epoch 123/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0985 - r_square: 0.2942\n",
      "Epoch 124/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0970 - r_square: 0.3033\n",
      "Epoch 125/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0955 - r_square: 0.3135\n",
      "Epoch 126/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0939 - r_square: 0.3197\n",
      "Epoch 127/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0923 - r_square: 0.3313\n",
      "Epoch 128/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0907 - r_square: 0.3367\n",
      "Epoch 129/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0891 - r_square: 0.3458\n",
      "Epoch 130/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0874 - r_square: 0.3550\n",
      "Epoch 131/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0857 - r_square: 0.3626\n",
      "Epoch 132/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0840 - r_square: 0.3704\n",
      "Epoch 133/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0824 - r_square: 0.3816\n",
      "Epoch 134/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0807 - r_square: 0.3914\n",
      "Epoch 135/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0790 - r_square: 0.3984\n",
      "Epoch 136/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0773 - r_square: 0.4082\n",
      "Epoch 137/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0756 - r_square: 0.4150\n",
      "Epoch 138/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0739 - r_square: 0.4267\n",
      "Epoch 139/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0722 - r_square: 0.4370\n",
      "Epoch 140/140\n",
      "69/69 [==============================] - 0s 1ms/step - loss: 0.0706 - r_square: 0.4458\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0621 - r_square: 0.5232\n",
      "Test loss: [0.0620780810713768, 0.523173451423645]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_addons.metrics import RSquare\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=opt, metrics=[RSquare()])\n",
    "model.fit(X_train, y_train,epochs=140)\n",
    "\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', loss)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predicted values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 727us/step\n",
      "0.5231729774229245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(r2_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
