{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CatBoost\n",
    "\n",
    "The goal of training is to select the model y, depending on a set of features Xi, that best solves the given problem for any input object.\n",
    "\n",
    "This model is found by using a training dataset, which is a set of objects with known features and label values. Accuracy is checked on the validation dataset, which has data in the same format as in the training dataset, but it is only used for evaluating the quality of training.\n",
    "\n",
    "CatBoost is based on gradient boosted decision trees. During training, a set of decision trees is built consecutively. Each successive tree is built with reduced loss compared to the previous ones.\n",
    "\n",
    "The number of trees is controlled by the starting parameters. To prevent overfitting, use the overfitting detector. When it is triggered, trees stop being built."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Number of trees\n",
    "It is recommended to check that there is no obvious underfitting or overfitting before tuning any other parameters. In order to do this it is necessary to analyze the metric value on the validation dataset and select the appropriate number of iterations.\n",
    "\n",
    "This can be done by setting the number of iterations to a large value, using the overfitting detector parameters and turning the use best model options on. In this case the resulting model contains only the first k best iterations, where k is the iteration with the best loss value on the validation dataset.\n",
    "\n",
    "Also, the metric for choosing the best model may differ from the one used for optimizing the objective value. For example, it is possible to set the optimized function to Logloss and use the AUC function for the overfitting detector. To do so, use the evaluation metric parameter."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "To employ param {'use_best_model': True} provide non-empty 'eval_set'.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mCatBoostError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_2856/3837189715.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 53\u001B[1;33m model.randomized_search(grid,\n\u001B[0m\u001B[0;32m     54\u001B[0m                   \u001B[0mtrain_dataset\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     55\u001B[0m                   \u001B[0my\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001B[0m in \u001B[0;36mrandomized_search\u001B[1;34m(self, param_distributions, X, y, cv, n_iter, partition_random_seed, calc_cv_statistics, search_by_train_test_split, refit, shuffle, stratified, train_size, verbose, plot, log_cout, log_cerr)\u001B[0m\n\u001B[0;32m   4117\u001B[0m                 \u001B[1;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Parameter grid value is not iterable and do not have \\'rvs\\' method (key={!r}, value={!r})'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparam_distributions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4118\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 4119\u001B[1;33m         return self._tune_hyperparams(\n\u001B[0m\u001B[0;32m   4120\u001B[0m             \u001B[0mparam_grid\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mparam_distributions\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcv\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_iter\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mn_iter\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4121\u001B[0m             \u001B[0mpartition_random_seed\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpartition_random_seed\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcalc_cv_statistics\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcalc_cv_statistics\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001B[0m in \u001B[0;36m_tune_hyperparams\u001B[1;34m(self, param_grid, X, y, cv, n_iter, partition_random_seed, calc_cv_statistics, search_by_train_test_split, refit, shuffle, stratified, train_size, verbose, plot, log_cout, log_cerr)\u001B[0m\n\u001B[0;32m   3883\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Parameter grid is not a dict or a list ({!r})'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparam_grid\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3884\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3885\u001B[1;33m         \u001B[0mtrain_params\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_prepare_train_params\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3886\u001B[0m         \u001B[0mparams\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_params\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"params\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3887\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001B[0m in \u001B[0;36m_prepare_train_params\u001B[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001B[0m\n\u001B[0;32m   2233\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2234\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_param\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'use_best_model'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0meval_total_row_count\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2235\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mCatBoostError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"To employ param {'use_best_model': True} provide non-empty 'eval_set'.\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2236\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2237\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0minit_model\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minit_model\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mPATH_TYPES\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mCatBoostError\u001B[0m: To employ param {'use_best_model': True} provide non-empty 'eval_set'."
     ]
    }
   ],
   "source": [
    "import catboost as cb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X_train = pd.read_csv('x_train_preprocessed.csv')\n",
    "X_test = pd.read_csv('x_test_preprocessed.csv')\n",
    "y_train = pd.read_csv('y_train_preprocessed.csv')\n",
    "y_test = pd.read_csv('y_test_preprocessed.csv')\n",
    "\n",
    "oh_neighbor = []\n",
    "for col in X_train.columns:\n",
    "       if 'Neighborhood_b' in col:\n",
    "              oh_neighbor.append(col)\n",
    "\n",
    "X_train.drop(columns=oh_neighbor, inplace=True)\n",
    "X_test.drop(columns=oh_neighbor, inplace=True)\n",
    "\n",
    "porch = ['Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch']\n",
    "surface = ['Total_Finished_Bsmt_SF', 'First_Flr_SF', 'Second_Flr_SF', 'Garage_Area']\n",
    "baths = ['Full_Bath', 'Half_Bath', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath']\n",
    "\n",
    "X_train.drop(columns=porch, inplace=True)\n",
    "X_test.drop(columns=porch, inplace=True)\n",
    "\n",
    "X_train.drop(columns=surface, inplace=True)\n",
    "X_test.drop(columns=surface, inplace=True)\n",
    "\n",
    "X_train.drop(columns=baths, inplace=True)\n",
    "X_test.drop(columns=baths, inplace=True)\n",
    "\n",
    "train_dataset = cb.Pool(X_train, y_train)\n",
    "test_dataset = cb.Pool(X_test, y_test)\n",
    "\n",
    "model = cb.CatBoostRegressor(loss_function='RMSE', task_type='GPU', devices='0:1',\n",
    "                             use_best_model=True, #Necessary to True for a high number of iterations\n",
    "                             eval_metric='RMSE',\n",
    "                             od_type='IncToDec',#Type of overfitting detector\n",
    "                             od_pval=.01, #threshold to stop overfitting detector range 10 alla meno 10 a 10 alla -2\n",
    "                             border_count=254,#The value of this parameter significantly impacts the speed of training on GPU. The smaller the value, the faster the training is performed (refer to the Number of splits for numerical features section for details).\n",
    "                             )\n",
    "\n",
    "grid = {'iterations': [100, 150, 200],  #The maximum number of trees that can be built\n",
    "        'learning_rate': [0.01,0.03,0.05, 0.1],   #Used for reducing the gradient step,\n",
    "        'depth': [6, 7, 8, 9, 10],\n",
    "        'l2_leaf_reg': [0.2, 0.5, 1, 3],\n",
    "        'random_strenght': [0.2,0.5,0.8]}\n",
    "\n",
    "#model.grid_search(grid, train_dataset, plot=True,cv=5,search_by_train_test_split=True,calc_cv_statistics=True)\n",
    "\n",
    "\n",
    "model.randomized_search(grid,\n",
    "                  train_dataset,\n",
    "                  y=None,\n",
    "                  cv=5,\n",
    "                  n_iter=10,\n",
    "                  partition_random_seed=0,\n",
    "                  calc_cv_statistics=True,\n",
    "                  search_by_train_test_split=True,\n",
    "                  refit=True,\n",
    "                  shuffle=True,\n",
    "                  stratified=None,\n",
    "                  train_size=0.8,\n",
    "                  verbose=True,\n",
    "                    )\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "rmse = (np.sqrt(mean_squared_error(y_test, pred)))\n",
    "r2 = r2_score(y_test, pred)\n",
    "\n",
    "print(\"Testing performance\")\n",
    "print('RMSE: {:.2f}'.format(rmse))\n",
    "print('R2: {:.2f}'.format(r2))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
