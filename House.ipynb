{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matti\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp/ipykernel_9056/1085272729.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_SS[col] = encoded[:, i]\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp/ipykernel_9056/1085272729.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_train_SS[col] = encoded[:, i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "[ 0  1  4  5  6  7  8  9 10 11 12 13 14 15 16 17 20 21 22 23 24 26 27 28\n",
      " 29 30 31 32 34 38 39 40 41 52 54 56 57 58 61 62 63 70 74 75]\n",
      "PRE\n",
      "372\n",
      "372\n",
      "POST\n",
      "328\n",
      "328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matti\\AppData\\Local\\Temp/ipykernel_9056/1085272729.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_SS[col] = encoded[:, i]\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp/ipykernel_9056/1085272729.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_test_SS[col] = encoded[:, i]\n",
      "C:\\Users\\matti\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Lot_Frontage  Lot_Area  Year_Built  Year_Remod_Add  Mas_Vnr_Area  \\\n0            141.0   31770.0      1960.0          1960.0         112.0   \n5             78.0    9978.0      1998.0          1998.0          20.0   \n6             41.0    4920.0      2001.0          2001.0           0.0   \n7             43.0    5005.0      1992.0          1992.0           0.0   \n13            85.0   10176.0      1990.0          1990.0           0.0   \n...            ...       ...         ...             ...           ...   \n2920          21.0    1894.0      1970.0          1970.0           0.0   \n2922          63.0    9297.0      1976.0          1976.0           0.0   \n2925          37.0    7937.0      1984.0          1984.0           0.0   \n2926           0.0    8885.0      1983.0          1983.0           0.0   \n2927          62.0   10441.0      1992.0          1992.0           0.0   \n\n      BsmtFin_SF_1  BsmtFin_SF_2  Bsmt_Unf_SF  Total_Bsmt_SF  First_Flr_SF  \\\n0              2.0           0.0        441.0         1080.0        1656.0   \n5              3.0           0.0        324.0          926.0         926.0   \n6              3.0           0.0        722.0         1338.0        1338.0   \n7              1.0           0.0       1017.0         1280.0        1280.0   \n13             3.0           0.0        663.0         1300.0        1341.0   \n...            ...           ...          ...            ...           ...   \n2920           6.0           0.0        294.0          546.0         546.0   \n2922           1.0           0.0        122.0         1728.0        1728.0   \n2925           3.0           0.0        184.0         1003.0        1003.0   \n2926           2.0         324.0        239.0          864.0         902.0   \n2927           3.0           0.0        575.0          912.0         970.0   \n\n      ...  x42_b'ConLw'  x42_b'New'  x42_b'Oth'  x42_b'WD '  x43_b'Abnorml'  \\\n0     ...           0.0         0.0         0.0         1.0             0.0   \n5     ...           0.0         0.0         0.0         1.0             0.0   \n6     ...           0.0         0.0         0.0         1.0             0.0   \n7     ...           0.0         0.0         0.0         1.0             0.0   \n13    ...           0.0         0.0         0.0         1.0             0.0   \n...   ...           ...         ...         ...         ...             ...   \n2920  ...           0.0         0.0         0.0         1.0             1.0   \n2922  ...           0.0         0.0         0.0         1.0             0.0   \n2925  ...           0.0         0.0         0.0         1.0             0.0   \n2926  ...           0.0         0.0         0.0         1.0             0.0   \n2927  ...           0.0         0.0         0.0         1.0             0.0   \n\n      x43_b'AdjLand'  x43_b'Alloca'  x43_b'Family'  x43_b'Normal'  \\\n0                0.0            0.0            0.0            1.0   \n5                0.0            0.0            0.0            1.0   \n6                0.0            0.0            0.0            1.0   \n7                0.0            0.0            0.0            1.0   \n13               0.0            0.0            0.0            1.0   \n...              ...            ...            ...            ...   \n2920             0.0            0.0            0.0            0.0   \n2922             0.0            0.0            1.0            0.0   \n2925             0.0            0.0            0.0            1.0   \n2926             0.0            0.0            0.0            1.0   \n2927             0.0            0.0            0.0            1.0   \n\n      x43_b'Partial'  \n0                0.0  \n5                0.0  \n6                0.0  \n7                0.0  \n13               0.0  \n...              ...  \n2920             0.0  \n2922             0.0  \n2925             0.0  \n2926             0.0  \n2927             0.0  \n\n[1462 rows x 328 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Lot_Frontage</th>\n      <th>Lot_Area</th>\n      <th>Year_Built</th>\n      <th>Year_Remod_Add</th>\n      <th>Mas_Vnr_Area</th>\n      <th>BsmtFin_SF_1</th>\n      <th>BsmtFin_SF_2</th>\n      <th>Bsmt_Unf_SF</th>\n      <th>Total_Bsmt_SF</th>\n      <th>First_Flr_SF</th>\n      <th>...</th>\n      <th>x42_b'ConLw'</th>\n      <th>x42_b'New'</th>\n      <th>x42_b'Oth'</th>\n      <th>x42_b'WD '</th>\n      <th>x43_b'Abnorml'</th>\n      <th>x43_b'AdjLand'</th>\n      <th>x43_b'Alloca'</th>\n      <th>x43_b'Family'</th>\n      <th>x43_b'Normal'</th>\n      <th>x43_b'Partial'</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>141.0</td>\n      <td>31770.0</td>\n      <td>1960.0</td>\n      <td>1960.0</td>\n      <td>112.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>441.0</td>\n      <td>1080.0</td>\n      <td>1656.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>78.0</td>\n      <td>9978.0</td>\n      <td>1998.0</td>\n      <td>1998.0</td>\n      <td>20.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>324.0</td>\n      <td>926.0</td>\n      <td>926.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>41.0</td>\n      <td>4920.0</td>\n      <td>2001.0</td>\n      <td>2001.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>722.0</td>\n      <td>1338.0</td>\n      <td>1338.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>43.0</td>\n      <td>5005.0</td>\n      <td>1992.0</td>\n      <td>1992.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1017.0</td>\n      <td>1280.0</td>\n      <td>1280.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>85.0</td>\n      <td>10176.0</td>\n      <td>1990.0</td>\n      <td>1990.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>663.0</td>\n      <td>1300.0</td>\n      <td>1341.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2920</th>\n      <td>21.0</td>\n      <td>1894.0</td>\n      <td>1970.0</td>\n      <td>1970.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>294.0</td>\n      <td>546.0</td>\n      <td>546.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2922</th>\n      <td>63.0</td>\n      <td>9297.0</td>\n      <td>1976.0</td>\n      <td>1976.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>122.0</td>\n      <td>1728.0</td>\n      <td>1728.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2925</th>\n      <td>37.0</td>\n      <td>7937.0</td>\n      <td>1984.0</td>\n      <td>1984.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>184.0</td>\n      <td>1003.0</td>\n      <td>1003.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2926</th>\n      <td>0.0</td>\n      <td>8885.0</td>\n      <td>1983.0</td>\n      <td>1983.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>324.0</td>\n      <td>239.0</td>\n      <td>864.0</td>\n      <td>902.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2927</th>\n      <td>62.0</td>\n      <td>10441.0</td>\n      <td>1992.0</td>\n      <td>1992.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>575.0</td>\n      <td>912.0</td>\n      <td>970.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1462 rows Ã— 328 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 216341484417.61417, tolerance: 669482758.2186916\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\matti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 243497964315.3779, tolerance: 717601550.9378058\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\matti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 217065470423.546, tolerance: 703985655.6190223\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\matti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 167099932913.8931, tolerance: 737579813.3297116\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\matti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 249027402632.92517, tolerance: 707818921.5207319\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90121674 0.90832057 0.71166997 0.62998136 0.92896822]\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\"\"\\n# instantiate the DecisionTreeClassifier model with criterion gini index\\nclf_gini = DecisionTreeClassifier(criterion=\\'gini\\', max_depth=100, random_state=0)\\n\\n\\n# fit the model\\nclf_gini.fit(X_train_SS, y_train_SS)\\n\\n\\ny_pred_gini = clf_gini.predict(X_test_SS)\\n\\n\\nfrom sklearn.metrics import accuracy_score\\n\\nprint(\\'Model accuracy score with criterion gini index: {0:0.4f}\\'. format(accuracy_score(y_test_SS, y_pred_gini)))\\n\\nprint(clf_gini)\\n'"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from scipy.io.arff import loadarff\n",
    "\n",
    "raw_data = loadarff('house.arff')\n",
    "df = pd.DataFrame(raw_data[0])\n",
    "\n",
    "#print(df['Misc_Feature'].unique())\n",
    "#Ridondanze: Pool_QC, Misc_Feature(?),\n",
    "#TODO CONTROLLARE in base anche a feature selection\n",
    "#df.drop(columns=['Pool_QC'], inplace=True)\n",
    "#df.drop(columns=['Misc_Val'], inplace=True)\n",
    "\n",
    "df.drop_duplicates(subset=['Longitude','Latitude'], keep='last',inplace=True)\n",
    "df.drop([\"Latitude\",\"Longitude\", \"Pool_QC\", \"Misc_Feature\"],axis = 1 , inplace=True)\n",
    "\n",
    "# drop label columns\n",
    "X = df.drop(columns=['Sale_Price'])\n",
    "\n",
    "# isolate y\n",
    "y = df.loc[:, 'Sale_Price']\n",
    "\n",
    "#splitter=StratifiedShuffleSplit(n_splits=1,random_state=12) #we can make a number of combinations of split\n",
    "skf = StratifiedKFold(n_splits=2, random_state=1, shuffle=True)\n",
    "\n",
    "#But we are interested in only one.\n",
    "\n",
    "for train,test in skf.split(X,y):     #this will splits the index\n",
    "    X_train_SS = X.iloc[train]\n",
    "    y_train_SS = y.iloc[train]\n",
    "    X_test_SS = X.iloc[test]\n",
    "    y_test_SS = y.iloc[test]\n",
    "\n",
    "#X_train_80, X_test, y_train_80, y_test = train_test_split(X, y, random_state=10)\n",
    "\n",
    "#encoded_X_train_80 = pd.get_dummies(X_train_SS)\n",
    "#encoded_X_test = pd.get_dummies(X_test_SS)\n",
    "#display(encoded_X_train_80)\n",
    "#display(encoded_X_test)\n",
    "\n",
    "#df = df.select_dtypes([np.object])\n",
    "#df = df.stack().str.decode('utf-8').unstack()\n",
    "#print(df.dtypes)\n",
    "\n",
    "is_numerical = np.array([is_numeric_dtype(X_train_SS[col]) for col in X_train_SS])\n",
    "#numerical_idx = np.flatnonzero(is_numerical)\n",
    "categorical_idx = np.flatnonzero(is_numerical==False)\n",
    "#print(numerical_idx, len(numerical_idx))\n",
    "print(len(categorical_idx))\n",
    "print(categorical_idx)\n",
    "\n",
    "oh = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "oh.fit(X_train_SS.iloc[:, categorical_idx])\n",
    "\n",
    "encoded = oh.transform(X_train_SS.iloc[:, categorical_idx])\n",
    "\n",
    "for i,col in enumerate(oh.get_feature_names()):\n",
    "    X_train_SS[col] = encoded[:, i]\n",
    "\n",
    "encoded = oh.transform(X_test_SS.iloc[:, categorical_idx])\n",
    "for i,col in enumerate(oh.get_feature_names()):\n",
    "    X_test_SS[col] = encoded[:, i]\n",
    "\n",
    "print(\"PRE\")\n",
    "print(len(X_train_SS.columns))\n",
    "print(len(X_test_SS.columns))\n",
    "\n",
    "X_train_SS.drop(columns=X_train_SS.columns[categorical_idx], inplace=True)\n",
    "X_test_SS.drop(columns=X_test_SS.columns[categorical_idx], inplace=True)\n",
    "\n",
    "print(\"POST\")\n",
    "print(len(X_train_SS.columns))\n",
    "print(len(X_test_SS.columns))\n",
    "\n",
    "display(X_train_SS)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(X_train_SS,y_train_SS)\n",
    "best_features = np.argsort(rf.feature_importances_)[::-1]\n",
    "\n",
    "sum = 0\n",
    "\n",
    "for bf in best_features:\n",
    "    sum += rf.feature_importances_[bf]\n",
    "\n",
    "print(sum)\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "lasso = linear_model.Lasso()\n",
    "print(cross_val_score(lasso, X_train_SS, y_train_SS))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\"\"\n",
    "# instantiate the DecisionTreeClassifier model with criterion gini index\n",
    "clf_gini = DecisionTreeClassifier(criterion='gini', max_depth=100, random_state=0)\n",
    "\n",
    "\n",
    "# fit the model\n",
    "clf_gini.fit(X_train_SS, y_train_SS)\n",
    "\n",
    "\n",
    "y_pred_gini = clf_gini.predict(X_test_SS)\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Model accuracy score with criterion gini index: {0:0.4f}'. format(accuracy_score(y_test_SS, y_pred_gini)))\n",
    "\n",
    "print(clf_gini)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "count           2931\n",
      "unique            29\n",
      "top       North_Ames\n",
      "freq             443\n",
      "Name: 12, dtype: object\n",
      "count        2931\n",
      "unique         18\n",
      "top       VinylSd\n",
      "freq         1015\n",
      "Name: 24, dtype: object\n",
      "2          MS_Zoning\n",
      "5             Street\n",
      "6              Alley\n",
      "7          Lot_Shape\n",
      "8       Land_Contour\n",
      "9          Utilities\n",
      "10        Lot_Config\n",
      "11        Land_Slope\n",
      "13       Condition_1\n",
      "14       Condition_2\n",
      "15         Bldg_Type\n",
      "16       House_Style\n",
      "18      Overall_Cond\n",
      "21        Roof_Style\n",
      "22         Roof_Matl\n",
      "25      Mas_Vnr_Type\n",
      "27        Exter_Qual\n",
      "28        Exter_Cond\n",
      "29        Foundation\n",
      "30         Bsmt_Qual\n",
      "31         Bsmt_Cond\n",
      "32     Bsmt_Exposure\n",
      "33    BsmtFin_Type_1\n",
      "34      BsmtFin_SF_1\n",
      "35    BsmtFin_Type_2\n",
      "39           Heating\n",
      "40        Heating_QC\n",
      "41       Central_Air\n",
      "42        Electrical\n",
      "47    Bsmt_Full_Bath\n",
      "48    Bsmt_Half_Bath\n",
      "49         Full_Bath\n",
      "50         Half_Bath\n",
      "51     Bedroom_AbvGr\n",
      "52     Kitchen_AbvGr\n",
      "53      Kitchen_Qual\n",
      "55        Functional\n",
      "56        Fireplaces\n",
      "57      Fireplace_Qu\n",
      "58       Garage_Type\n",
      "59     Garage_Finish\n",
      "60       Garage_Cars\n",
      "62       Garage_Qual\n",
      "63       Garage_Cond\n",
      "64       Paved_Drive\n",
      "71           Pool_QC\n",
      "72             Fence\n",
      "73      Misc_Feature\n",
      "76         Year_Sold\n",
      "78    Sale_Condition\n",
      "Name: 0, dtype: object\n",
      "-----------------\n",
      "<class 'str'>\n",
      "<bound method NDFrame.head of         id  MS_SubClass  MS_Zoning  Lot_Frontage  Lot_Area  Street  Alley  \\\n",
      "0        1            2          5           141     31770       1      1   \n",
      "1        2            2          4            80     11622       1      1   \n",
      "2        3            2          5            81     14267       1      1   \n",
      "3        4            2          5            93     11160       1      1   \n",
      "4        5           13          5            74     13830       1      1   \n",
      "...    ...          ...        ...           ...       ...     ...    ...   \n",
      "2925  2926           10          5            37      7937       1      1   \n",
      "2926  2927            2          5             0      8885       1      1   \n",
      "2927  2928            9          5            62     10441       1      1   \n",
      "2928  2929            2          5            77     10010       1      1   \n",
      "2929  2930           13          5            74      9627       1      1   \n",
      "\n",
      "      Lot_Shape  Land_Contour  Utilities  ...  Fence  Misc_Feature  Misc_Val  \\\n",
      "0             3             3          0  ...      4             2         0   \n",
      "1             2             3          0  ...      2             2         0   \n",
      "2             3             3          0  ...      4             1     12500   \n",
      "3             2             3          0  ...      4             2         0   \n",
      "4             3             3          0  ...      2             2         0   \n",
      "...         ...           ...        ...  ...    ...           ...       ...   \n",
      "2925          3             3          0  ...      0             2         0   \n",
      "2926          3             2          0  ...      2             2         0   \n",
      "2927          2             3          0  ...      2             4       700   \n",
      "2928          2             3          0  ...      4             2         0   \n",
      "2929          2             3          0  ...      4             2         0   \n",
      "\n",
      "      Mo_Sold  Year_Sold  Sale_Type  Sale_Condition  Sale_Price  Longitude  \\\n",
      "0           5       2010          9               4      215000  -93619754   \n",
      "1           6       2010          9               4      105000  -93619756   \n",
      "2           6       2010          9               4      172000  -93619387   \n",
      "3           4       2010          9               4      244000   -9361732   \n",
      "4           3       2010          9               4      189900  -93638933   \n",
      "...       ...        ...        ...             ...         ...        ...   \n",
      "2925        3       2006          9               4      142500  -93604776   \n",
      "2926        6       2006          9               4      131000   -9360268   \n",
      "2927        7       2006          9               4      132000  -93606847   \n",
      "2928        4       2006          9               4      170000   -9360019   \n",
      "2929       11       2006          9               4      188000  -93599996   \n",
      "\n",
      "      Latitude  \n",
      "0     42054035  \n",
      "1     42053014  \n",
      "2     42052659  \n",
      "3     42051245  \n",
      "4     42060899  \n",
      "...        ...  \n",
      "2925  41988964  \n",
      "2926  41988314  \n",
      "2927   4198651  \n",
      "2928  41990921  \n",
      "2929  41989265  \n",
      "\n",
      "[2930 rows x 82 columns]>\n",
      "-----------------\n",
      "Index(['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Lot_Area', 'Street',\n",
      "       'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config',\n",
      "       'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type',\n",
      "       'House_Style', 'Overall_Qual', 'Overall_Cond', 'Year_Built',\n",
      "       'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st',\n",
      "       'Exterior_2nd', 'Mas_Vnr_Type', 'Mas_Vnr_Area', 'Exter_Qual',\n",
      "       'Exter_Cond', 'Foundation', 'Bsmt_Qual', 'Bsmt_Cond', 'Bsmt_Exposure',\n",
      "       'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2',\n",
      "       'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air',\n",
      "       'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Low_Qual_Fin_SF',\n",
      "       'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath',\n",
      "       'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'Kitchen_Qual',\n",
      "       'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Fireplace_Qu',\n",
      "       'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area',\n",
      "       'Garage_Qual', 'Garage_Cond', 'Paved_Drive', 'Wood_Deck_SF',\n",
      "       'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch',\n",
      "       'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold',\n",
      "       'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Sale_Price', 'Longitude',\n",
      "       'Latitude'],\n",
      "      dtype='object')\n",
      "[2.03890784e-05 1.06048900e-04 3.28510990e-05 4.86277571e-05\n",
      " 5.81380664e-08 1.01583237e-05 1.74864337e-05 3.16994410e-06\n",
      " 1.75748396e-09 5.90274143e-06 6.34507903e-07 3.77610332e-03\n",
      " 2.08224479e-05 2.43358695e-07 9.62067848e-06 6.36993897e-06\n",
      " 1.64579025e-05 6.74307655e-06 4.53365247e-04 4.01835686e-05\n",
      " 1.78711398e-06 6.49847911e-08 2.62840622e-05 1.13145895e-05\n",
      " 1.14620557e-05 1.41635823e-05 1.19562811e-05 3.30178816e-06\n",
      " 1.03241307e-05 1.85913901e-05 1.54522158e-06 8.94897868e-06\n",
      " 8.38042497e-06 8.40248855e-06 6.76103596e-06 3.05592480e-06\n",
      " 8.43053754e-05 2.28290908e-05 5.06975394e-07 2.73608697e-05\n",
      " 9.04049373e-07 9.69473130e-07 6.65175268e-05 2.35340156e-05\n",
      " 2.71252371e-07 3.03367626e-05 1.12052630e-05 5.23833293e-06\n",
      " 8.03115964e-06 3.89113368e-06 9.16816359e-06 2.62619974e-06\n",
      " 1.13941503e-05 1.84631967e-05 2.33618783e-06 3.05868065e-06\n",
      " 1.40787601e-05 2.12150030e-05 1.15776973e-05 1.09654013e-05\n",
      " 3.91161233e-05 2.05479906e-06 1.51368184e-06 2.51418523e-06\n",
      " 1.95035303e-05 1.93585691e-05 5.11571813e-06 1.72487781e-06\n",
      " 1.21316281e-05 1.14015068e-09 1.02750548e-09 8.38523680e-06\n",
      " 3.50440784e-07 7.64352056e-06 2.24285447e-05 9.54870241e-01\n",
      " 2.24761210e-06 2.76203768e-06 5.52127742e-05 1.38761125e-03\n",
      " 3.84277150e-02]\n",
      "[ 0.06757546  0.1070241   0.00259321  0.02436278 -0.13080127]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#CON HEADER NONE\n",
    "X = df.loc[:,1:]\n",
    "# get class label\n",
    "y = df.loc[:,0]\n",
    "print(\"----------------------------\")\n",
    "#SENZA HEADER A NONE PER USARE NOME COLONNE\n",
    "\n",
    "df = pd.read_csv('house.csv',sep=';')\n",
    "X = df.loc[:,'MS_SubClass':]\n",
    "print('-----------------')\n",
    "y = df.loc[:,'id']\n",
    "\n",
    "print(type(df['MS_SubClass'][0]))\n",
    "#TRY TO COMPUTER LABEL ENCODER\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(df['MS_SubClass'])\n",
    "df['MS_SubClass'] = le.transform(df['MS_SubClass'])\n",
    "import numpy as np\n",
    "for column in df:\n",
    "    if df[column].dtype == 'object':\n",
    "        le.fit(df[column])\n",
    "        df[column] = le.transform(df[column])\n",
    "\n",
    "print(df.head)\n",
    "X = df.loc[:,'MS_SubClass':]\n",
    "print('-----------------')\n",
    "y = df.loc[:,'id']\n",
    "feature_names = df.columns[1:]\n",
    "print(feature_names)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(X,y)\n",
    "print(rf.feature_importances_)\n",
    "\n",
    "best_features = np.argsort(rf.feature_importances_)[::-1]\n",
    "\n",
    "rmse = []\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "lasso = linear_model.Lasso()\n",
    "print(cross_val_score(lasso, X, y))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tsfresh'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_9140/3327063228.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtsfresh\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mextract_features\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtsfresh\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mfeature_selection\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'tsfresh'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tsfresh import extract_features\n",
    "from tsfresh import feature_selection\n",
    "\n",
    "df = pd.read_csv('house.csv',sep=';',header=None)\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Misc_Val -> valore della feature\n",
    "#Misc_Feature -> togliamo ??\n",
    "\n",
    "#Condition 2 -> 2900 Norm su 2931  -> rimuovere\n",
    "\n",
    "#Roof_Matl -> rimovere troppo uguali\n",
    "#Piscina con campo a None\n",
    "#Street -> 13 diversi da Pavel levare\n",
    "\n",
    "#Utilities -> levare troppi pochi campi diversi\n",
    "\n",
    "#anno ristrutturazione come unico Anno\n",
    "\n",
    "\"\"\"\"\"\n",
    "#decidere se tenere una o eliminare tutte le righe con longitudine e latitudine uguale\n",
    "df = df.drop_duplicates(subset=['Longitude','Latitude'], keep='last',inplace=False)\n",
    "df.drop([\"Latitude\",\"Longitude\"],axis = 1 , inplace=True)\n",
    "\n",
    "\n",
    "columns_to_drop = []\n",
    "for column in df:\n",
    "    val = df[column].value_counts().idxmax()\n",
    "    if df[column].eq(val).mean() > 0.9:\n",
    "        columns_to_drop.append(column)\n",
    "df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "#print(columns_to_drop)\n",
    "#print(df.info())\n",
    "\n",
    "\n",
    "\"\"\"\"\"\n",
    "\"\"\"\"\"\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(np.unique(df.drop('Lot_Frontage', axis=1)))\n",
    "X = np.array([le.transform(samp) for samp in df.drop('Lot_Frontage', axis=1).values])\n",
    "print(\"-------------------\")\n",
    "print(df['LotFrontage'])\n",
    "print(\"-------------------\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get features by removing id and class\n",
    "# remove id\n",
    "X = df.loc[:,]\n",
    "print(\"X shape\", X.shape)\n",
    "\n",
    "# get class label\n",
    "\"\"\"\"\"\n",
    "\"\"\"\"\"\n",
    "y = df.loc[:,]\n",
    "print(\"y shape\", y.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(np.unique(df.drop('Lot_Frontage', axis=1)))\n",
    "X = np.array([le.transform(samp) for samp in df.drop('Lot_Frontage', axis=1).values])\n",
    "print(\"-------------------\")\n",
    "print(df['LotFrontage'])\n",
    "print(\"-------------------\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(df)\n",
    "X = df.loc[:,1:]\n",
    "print(\"X shape\", X.shape)\n",
    "\n",
    "# get class label\n",
    "y = df.loc[:,0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(X,y)\n",
    "rf.feature_importances_\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,4))\n",
    "ax.bar(range(0,X.shape[1]), rf.feature_importances_)\n",
    "ax.set_title(\"Feature Importances\")\n",
    "ax.set_xticks(range(X.shape[1]))\n",
    "ax.set_xticklabels(df.feature_names)\n",
    "ax.grid();\n",
    "\n",
    "\"\"\"\"\"\n",
    "for k in range(1,11):\n",
    "\n",
    "    kNN = KNeighborsClassifier(n_neighbors=k)\n",
    "    kNN.fit( scaler.transform(X_train), y_train )\n",
    "    y_pred = kNN.predict( scaler.transform(X_test) )\n",
    "\n",
    "    # compute Accuracy\n",
    "    acc = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "    print (\"k: {:2d} | Accuracy {:.3f}\".format(k,acc) )\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
