{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## KNN ALGORITHM\n",
    "The k-nearest neighbors algorithm, also known as KNN or k-NN, is a non-parametric, supervised learning regressor, which uses proximity to make predictions about the grouping of an individual data point. While it can be used for either regression or classification problems, it is typically used as a classification algorithm, working off the assumption that similar points can be found near one another.\n",
    "\n",
    "- Knn-Regression works by finding the k-nearest data points to the point we want to predict, and then taking the mean of their target values as the prediction.\n",
    "\n",
    "1) After choosing the number of k nearest neighbors that will be used to make the prediction,\n",
    "2) it calculates the distance between the point to be predicted and all the other points in the dataset then find the k points in the dataset that are closest to the point to be predicted.\n",
    "3) Finally, it takes the mean of the target values of the k-nearest points. This mean value is the prediction for the point to be predicted.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Differences between Minmax and SS\n",
    "At first, we try to run the algorithm with two different normalized dataset to understand which one is the best because it can vary based on the distribution of data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter_ 1 TRAIN:  0.999995556064519 , TEST:  0.6548162930324317\n",
      "n_iter_ 2 TRAIN:  0.9040245526188013 , TEST:  0.7306352206587241\n",
      "n_iter_ 3 TRAIN:  0.8686925706979628 , TEST:  0.7438862499080493\n",
      "n_iter_ 4 TRAIN:  0.8432623458644879 , TEST:  0.7614987131490388\n",
      "n_iter_ 5 TRAIN:  0.8286652591564905 , TEST:  0.7619037890590099\n",
      "n_iter_ 6 TRAIN:  0.8181674269402867 , TEST:  0.7720531882337277\n",
      "n_iter_ 7 TRAIN:  0.8129233702437663 , TEST:  0.7815060639119966\n",
      "n_iter_ 8 TRAIN:  0.8039981380895762 , TEST:  0.7815980177695694\n",
      "n_iter_ 9 TRAIN:  0.7981602884602009 , TEST:  0.7844442765562456\n",
      "n_iter_ 10 TRAIN:  0.7925707344398562 , TEST:  0.7845447223803126\n",
      "n_iter_ 11 TRAIN:  0.7871256105650429 , TEST:  0.7844038103053651\n",
      "n_iter_ 12 TRAIN:  0.78268666867862 , TEST:  0.7895855174808046\n",
      "n_iter_ 13 TRAIN:  0.7775245014153158 , TEST:  0.7874934790378751\n",
      "n_iter_ 14 TRAIN:  0.7735572484377018 , TEST:  0.7860394075985018\n",
      "n_iter_ 15 TRAIN:  0.7691026873392809 , TEST:  0.7841251587065841\n",
      "n_iter_ 16 TRAIN:  0.7661673686215941 , TEST:  0.7829414734717793\n",
      "n_iter_ 17 TRAIN:  0.7631741815232019 , TEST:  0.7819018649518892\n",
      "n_iter_ 18 TRAIN:  0.7593395041960027 , TEST:  0.7783116714212449\n",
      "n_iter_ 19 TRAIN:  0.7562698534055289 , TEST:  0.7750345257674156\n",
      "n_iter_ 20 TRAIN:  0.7520534295253297 , TEST:  0.7737920930777752\n",
      "n_iter_ 21 TRAIN:  0.750032582703146 , TEST:  0.7752259517150651\n",
      "n_iter_ 22 TRAIN:  0.7460959046050942 , TEST:  0.7728482532538485\n",
      "n_iter_ 23 TRAIN:  0.7429796035698457 , TEST:  0.7720956211325334\n",
      "n_iter_ 24 TRAIN:  0.7413327460237216 , TEST:  0.769947383233305\n",
      "n_iter_ 25 TRAIN:  0.7389674552347858 , TEST:  0.7688749276088713\n",
      "n_iter_ 26 TRAIN:  0.7370981860134189 , TEST:  0.7692038414395965\n",
      "n_iter_ 27 TRAIN:  0.7360583488824682 , TEST:  0.7676619500630285\n",
      "n_iter_ 28 TRAIN:  0.7343480540598479 , TEST:  0.7656296823155352\n",
      "n_iter_ 29 TRAIN:  0.7319193722479872 , TEST:  0.7640009291140495\n",
      "n_iter_ 30 TRAIN:  0.7291805345322844 , TEST:  0.7636673668857735\n",
      "n_iter_ 31 TRAIN:  0.7271739698069654 , TEST:  0.7633564694207468\n",
      "n_iter_ 32 TRAIN:  0.7262028800504615 , TEST:  0.7619102303655526\n",
      "n_iter_ 33 TRAIN:  0.7243923963919274 , TEST:  0.7612061552905445\n",
      "n_iter_ 34 TRAIN:  0.7229282350956031 , TEST:  0.7589631373695842\n",
      "n_iter_ 35 TRAIN:  0.7208107384063982 , TEST:  0.7565901002924237\n",
      "n_iter_ 36 TRAIN:  0.7186546478335938 , TEST:  0.7549622676680124\n",
      "n_iter_ 37 TRAIN:  0.7171676395112978 , TEST:  0.7519208499628208\n",
      "n_iter_ 38 TRAIN:  0.7165061702579612 , TEST:  0.7502419132291167\n",
      "n_iter_ 39 TRAIN:  0.7151105121896516 , TEST:  0.7495526356878022\n",
      "n_iter_ 40 TRAIN:  0.7129171708587447 , TEST:  0.7484219267782823\n",
      "n_iter_ 41 TRAIN:  0.7106987787513455 , TEST:  0.7474993756839099\n",
      "n_iter_ 42 TRAIN:  0.7092953705403555 , TEST:  0.7463949803287468\n",
      "n_iter_ 43 TRAIN:  0.7076259401772774 , TEST:  0.7447740725223886\n",
      "n_iter_ 44 TRAIN:  0.7066782405150127 , TEST:  0.7444484137775579\n",
      "n_iter_ 45 TRAIN:  0.7052006289978701 , TEST:  0.7422929664683529\n",
      "n_iter_ 46 TRAIN:  0.7037887049269766 , TEST:  0.7418837411738916\n",
      "n_iter_ 47 TRAIN:  0.701942835827889 , TEST:  0.7413289680886814\n",
      "n_iter_ 48 TRAIN:  0.7007175628439258 , TEST:  0.7404593197248865\n",
      "n_iter_ 49 TRAIN:  0.6994180740289773 , TEST:  0.7406208897995714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import pandas as pd\n",
    "\n",
    "X_train = pd.read_csv('x_train_preprocessed_minmax.csv')\n",
    "X_test = pd.read_csv('x_test_preprocessed_minmax.csv')\n",
    "y_train = pd.read_csv('y_train_preprocessed_minmax.csv')\n",
    "y_test = pd.read_csv('y_test_preprocessed_minmax.csv')\n",
    "\n",
    "for k in range(1,50):\n",
    "    kNN = KNeighborsRegressor(n_neighbors=k, weights='uniform', algorithm='auto', leaf_size=50, n_jobs=-1)\n",
    "\n",
    "    kNN.fit(X_train,y_train)\n",
    "    print(\"n_iter_\",k,\"TRAIN: \",kNN.score(X_train,y_train),\", TEST: \",kNN.score(X_test,y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter_ 1 TRAIN:  0.999995556064519 , TEST:  0.7341107423159402\n",
      "n_iter_ 2 TRAIN:  0.9239282321866633 , TEST:  0.7843391542310382\n",
      "n_iter_ 3 TRAIN:  0.8845033020614547 , TEST:  0.8047429091469638\n",
      "n_iter_ 4 TRAIN:  0.8557651900725336 , TEST:  0.8108380255069882\n",
      "n_iter_ 5 TRAIN:  0.8385545348405409 , TEST:  0.8181521804541428\n",
      "n_iter_ 6 TRAIN:  0.8343931856569102 , TEST:  0.8136496625454154\n",
      "n_iter_ 7 TRAIN:  0.8285442112490753 , TEST:  0.8134753915884895\n",
      "n_iter_ 8 TRAIN:  0.8209914177815101 , TEST:  0.8143971882725571\n",
      "n_iter_ 9 TRAIN:  0.8195809914274905 , TEST:  0.8097621894962198\n",
      "n_iter_ 10 TRAIN:  0.8142898417549622 , TEST:  0.8080765603696098\n",
      "n_iter_ 11 TRAIN:  0.8108614148288164 , TEST:  0.8104540302623253\n",
      "n_iter_ 12 TRAIN:  0.8088114323221752 , TEST:  0.8138451555359058\n",
      "n_iter_ 13 TRAIN:  0.8061429403552252 , TEST:  0.8119898223464308\n",
      "n_iter_ 14 TRAIN:  0.8013940744444299 , TEST:  0.8096252888758164\n",
      "n_iter_ 15 TRAIN:  0.7989302271772308 , TEST:  0.806962282102901\n",
      "n_iter_ 16 TRAIN:  0.7958014503647188 , TEST:  0.8092773996385747\n",
      "n_iter_ 17 TRAIN:  0.7917138361685021 , TEST:  0.8085367184504608\n",
      "n_iter_ 18 TRAIN:  0.789082247570462 , TEST:  0.8081631463715993\n",
      "n_iter_ 19 TRAIN:  0.7871480822584744 , TEST:  0.8060549895639235\n",
      "n_iter_ 20 TRAIN:  0.7848892934305391 , TEST:  0.804948676998652\n",
      "n_iter_ 21 TRAIN:  0.7820315246080259 , TEST:  0.802808925127299\n",
      "n_iter_ 22 TRAIN:  0.7804397711182208 , TEST:  0.8008912427675304\n",
      "n_iter_ 23 TRAIN:  0.7782088014360444 , TEST:  0.8004122377824486\n",
      "n_iter_ 24 TRAIN:  0.7766984620974678 , TEST:  0.7992834346804164\n",
      "n_iter_ 25 TRAIN:  0.7744297111824535 , TEST:  0.796272379414105\n",
      "n_iter_ 26 TRAIN:  0.7732953090404103 , TEST:  0.7946233330356417\n",
      "n_iter_ 27 TRAIN:  0.7715341894129782 , TEST:  0.7934691768609423\n",
      "n_iter_ 28 TRAIN:  0.7707827093286567 , TEST:  0.7919771982316546\n",
      "n_iter_ 29 TRAIN:  0.7706188971265868 , TEST:  0.7926486794442115\n",
      "n_iter_ 30 TRAIN:  0.769568429324121 , TEST:  0.7912706652861476\n",
      "n_iter_ 31 TRAIN:  0.7677582566391589 , TEST:  0.7897204302512852\n",
      "n_iter_ 32 TRAIN:  0.7664009386298953 , TEST:  0.7889002825537788\n",
      "n_iter_ 33 TRAIN:  0.7645053267303289 , TEST:  0.7884223938577004\n",
      "n_iter_ 34 TRAIN:  0.7630859255011058 , TEST:  0.7887905546991765\n",
      "n_iter_ 35 TRAIN:  0.7613863663273943 , TEST:  0.7875626220479883\n",
      "n_iter_ 36 TRAIN:  0.7603459342511474 , TEST:  0.7868670687486806\n",
      "n_iter_ 37 TRAIN:  0.7584480775941234 , TEST:  0.7855818976860891\n",
      "n_iter_ 38 TRAIN:  0.7571766417938002 , TEST:  0.7848541001054259\n",
      "n_iter_ 39 TRAIN:  0.755761491832924 , TEST:  0.7837637704605125\n",
      "n_iter_ 40 TRAIN:  0.7541731370357371 , TEST:  0.7827570435318467\n",
      "n_iter_ 41 TRAIN:  0.7531832621469401 , TEST:  0.7826856336434517\n",
      "n_iter_ 42 TRAIN:  0.7520083037107396 , TEST:  0.7818747579564536\n",
      "n_iter_ 43 TRAIN:  0.7504053234160017 , TEST:  0.7807402375340289\n",
      "n_iter_ 44 TRAIN:  0.7496640955531956 , TEST:  0.7796383600234518\n",
      "n_iter_ 45 TRAIN:  0.7482009730138615 , TEST:  0.7795328166046699\n",
      "n_iter_ 46 TRAIN:  0.7466675346854021 , TEST:  0.7783688783820477\n",
      "n_iter_ 47 TRAIN:  0.74513960401953 , TEST:  0.7770392811634882\n",
      "n_iter_ 48 TRAIN:  0.7439357881591947 , TEST:  0.7765670114133923\n",
      "n_iter_ 49 TRAIN:  0.7430395688330947 , TEST:  0.774997155455551\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv('x_train_preprocessed.csv')\n",
    "X_test = pd.read_csv('x_test_preprocessed.csv')\n",
    "y_train = pd.read_csv('y_train_preprocessed.csv')\n",
    "y_test = pd.read_csv('y_test_preprocessed.csv')\n",
    "\n",
    "\n",
    "for k in range(1,50):\n",
    "    kNN = KNeighborsRegressor(n_neighbors=k, weights='uniform', algorithm='auto', leaf_size=50, n_jobs=-1)\n",
    "\n",
    "    kNN.fit(X_train,y_train)\n",
    "    print(\"n_iter_\",k, \"TRAIN: \",kNN.score(X_train,y_train),\", TEST: \",kNN.score(X_test,y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Best scaling depends on data\n",
    "- **StandardScaler** does not remap every feature into the interval 0-1, but it depends on variance. A feature with a large variance may strongly impact on the overall distance\n",
    "- **MinMaxScaling** is usually more sensitive to outliers, but weights features more evenly\n",
    "- Euclidean Distance assumes all features are equally important, and this is usually not the case\n",
    "**In our case the algorithm seems to be working better with a SS normalization, so we continue with that.**\n",
    "Arriviamo a questa considerazione osservando i valori ottenuti dai due differenti test, si può notare molto facilmente come con SS si riesca ad ottenere una migliore precisione a discapito di un lieve overffiting mentre usando MinMax possiamo notare come in tutte le osservazioni i valori fra TEST e TRAIN sono simili e quindi l'algoritmo è piu' stabile."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Remove some features to see if the algorithm work better\n",
    "Based on the idea of the k-nn algorithm we could expect that dropping some features that should not be important will not modify the behavior / r^2 we get.\n",
    "Since the k-nn algorithm select the best ones based on the k parameter."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN  1 :  0.999995556064519 , TEST  1 :  0.680007639337778\n",
      "TRAIN  2 :  0.9131524907229598 , TEST  2 :  0.7390203275564162\n",
      "TRAIN  3 :  0.8635235026374533 , TEST  3 :  0.757524765293857\n",
      "TRAIN  4 :  0.8289474291787493 , TEST  4 :  0.7587567914732702\n",
      "TRAIN  5 :  0.8126653527470866 , TEST  5 :  0.7645733030090183\n",
      "TRAIN  6 :  0.801824033807873 , TEST  6 :  0.7716116991319467\n",
      "TRAIN  7 :  0.7935786550103925 , TEST  7 :  0.78034358534564\n",
      "TRAIN  8 :  0.7904745795250236 , TEST  8 :  0.7824203665578333\n",
      "TRAIN  9 :  0.7861069957706673 , TEST  9 :  0.7773828713800537\n",
      "TRAIN  10 :  0.7826504655019403 , TEST  10 :  0.7808421776185573\n",
      "TRAIN  11 :  0.7814800838603049 , TEST  11 :  0.7829142622677039\n",
      "TRAIN  12 :  0.7767103348571357 , TEST  12 :  0.7822102280051103\n",
      "TRAIN  13 :  0.7739589704751667 , TEST  13 :  0.7818693128276317\n",
      "TRAIN  14 :  0.7722847686959927 , TEST  14 :  0.7839116947625162\n",
      "TRAIN  15 :  0.7685102795821933 , TEST  15 :  0.7862896016239149\n",
      "TRAIN  16 :  0.7689706780268877 , TEST  16 :  0.7844919532116879\n",
      "TRAIN  17 :  0.7672667679920352 , TEST  17 :  0.7871278823465722\n",
      "TRAIN  18 :  0.7651903928499926 , TEST  18 :  0.7860265259742422\n",
      "TRAIN  19 :  0.7635692976841386 , TEST  19 :  0.7887843761329909\n"
     ]
    }
   ],
   "source": [
    "oh_neighbor = []\n",
    "for col in X_train.columns:\n",
    "    if 'Neighborhood_b' in col:\n",
    "        oh_neighbor.append(col)\n",
    "\n",
    "X_train_modified = X_train.drop(columns=oh_neighbor)\n",
    "X_test_modified= X_test.drop(columns=oh_neighbor)\n",
    "\n",
    "porch = ['Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch']\n",
    "surface = ['Total_Finished_Bsmt_SF', 'First_Flr_SF', 'Second_Flr_SF', 'Garage_Area']\n",
    "baths = ['Full_Bath', 'Half_Bath', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath']\n",
    "\n",
    "X_train_modified = X_train_modified.drop(columns=porch)\n",
    "X_test_modified = X_test_modified.drop(columns=porch)\n",
    "\n",
    "X_train_modified = X_train_modified.drop(columns=surface)\n",
    "X_test_modified = X_test_modified.drop(columns=surface)\n",
    "\n",
    "X_train_modified = X_train_modified.drop(columns=baths)\n",
    "X_test_modified = X_test_modified.drop(columns=baths)\n",
    "\n",
    "for k in range(1,20):\n",
    "    kNN = KNeighborsRegressor(n_neighbors=k, weights='uniform', algorithm='auto', leaf_size=50, n_jobs=-1)\n",
    "\n",
    "    kNN.fit(X_train_modified,y_train)\n",
    "    print(\"TRAIN \",k,\": \",kNN.score(X_train_modified,y_train),\", TEST \",k,\": \",kNN.score(X_test_modified,y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the r^2 is reduced, probably some feature removed\n",
    "accurately explained the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameters tuning\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 800 candidates, totalling 1600 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(cv=2, estimator=KNeighborsRegressor(), n_jobs=-1,\n             param_grid={'algorithm': ['auto'], 'leaf_size': range(10, 50),\n                         'n_jobs': [-1], 'n_neighbors': range(5, 15),\n                         'p': [1, 2], 'weights': ['uniform']},\n             scoring='r2', verbose=3)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters={\"n_neighbors\":range(5,15), #based on the observation made before choose a correlated range of n neighbors\n",
    "            \"weights\" : [\"uniform\"], # weights of objects based on :\n",
    "            # uniform = All points in each neighborhood are weighted equally / distance = weight points by the inverse of their distance. Closer cause more influence\n",
    "            \"algorithm\":[\"auto\"], #type of algorithm used\n",
    "            \"leaf_size\":range(10,50),\n",
    "            \"p\":[1,2],\n",
    "            \"n_jobs\":[-1] }\n",
    "\n",
    "reg_decision_model=KNeighborsRegressor()\n",
    "\n",
    "tuning_model=GridSearchCV(\n",
    "    reg_decision_model,param_grid=parameters,\n",
    "    scoring='r2'\n",
    "    ,cv=2, # cv fold low because when selecting a certain number of neighboors the algorithm will \"become deterministic\"\n",
    "    verbose=3,n_jobs= -1)\n",
    "\n",
    "tuning_model.fit(X_train,y_train)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Final results\n",
    "Show parameters selected by CV grid and score result on dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter selected by CV grid execution {'algorithm': 'auto', 'leaf_size': 10, 'n_jobs': -1, 'n_neighbors': 7, 'p': 1, 'weights': 'uniform'}\n",
      "Scoro R2 on train data 0.8631381022347369\n",
      "Score R2 on test data 0.8628416503608851\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameter selected by CV grid execution\",tuning_model.best_params_)\n",
    "\n",
    "print(\"Scoro R2 on train data\",tuning_model.score(X_train,y_train)) # Test model on our test split\n",
    "print(\"Score R2 on test data\",tuning_model.score(X_test,y_test)) # Test model on our test split"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
